{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4906784d",
   "metadata": {},
   "source": [
    "# Homework 3 - Attacks and Defenses in Federated Learning\n",
    "\n",
    "## infrastructure\n",
    "\n",
    "Based on a variant of FedAvg that updates parameter differences rather than a complete.\n",
    "As regular FedAvg, this variant performs multiple local epochs.\n",
    "Unlike regular FedAvg, clients now determine the deviation of their local parameters from the servers' parameters and upload the differences to the server.\n",
    "Perhaps surprisingly, these differences are referred to as \"gradients\".\n",
    "\n",
    "This variant is pretty much equivalent to the original one but makes it easier to reason about updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef411072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also includes all the dependencies of this module, as the dependencies are members of that module\n",
    "import typing\n",
    "\n",
    "from fedavg import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(f\"Using accelerator '{device}'\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARN: No accelerator found, running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradWeightClient(Client):\n",
    "    def __init__(\n",
    "        self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int\n",
    "    ) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # Load the server weights into the model\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Save initial weights to calculate the gradients later\n",
    "        initial_weights = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        for _epoch in range(self.nr_epochs):\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        # Calculate gradients: initial_weights - final_weights\n",
    "        gradients = [\n",
    "            initial_weight - final_weight\n",
    "            for final_weight, initial_weight in zip(\n",
    "                self.model.parameters(), initial_weights\n",
    "            )\n",
    "        ]\n",
    "        return [gradient.detach().cpu().clone() for gradient in gradients]\n",
    "\n",
    "\n",
    "class FedAvgGradServer(DecentralizedServer, ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        client_subsets: list[Subset],\n",
    "        client_fraction: float,\n",
    "        nr_local_epochs: int,\n",
    "        seed: int,\n",
    "    ) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            GradWeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets\n",
    "        ]\n",
    "\n",
    "\n",
    "def is_client_benign(client: Client) -> bool:\n",
    "    # benign clients are instances of 'GradWeightClient', malicious clients are subtypes\n",
    "    return type(client) == GradWeightClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db97c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "type SplitDataset = typing.Sequence[torch.utils.data.Dataset[typing.Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3e1ca",
   "metadata": {},
   "source": [
    "### attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackerGradientReversion(GradWeightClient):\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # Call the base implementation to perform the normal training and update process\n",
    "        honest_gradients = super().update(weights, seed)\n",
    "\n",
    "        # Reverse the gradients: for a malicious client, negate the weights to simulate an attack\n",
    "        reversed_gradients = [-5*w for w in honest_gradients]\n",
    "    \n",
    "\n",
    "        return reversed_gradients\n",
    "\n",
    "def build_gradient_reversion_client(\n",
    "    client_data: torch.utils.data.Dataset[typing.Any],\n",
    "    learning_rate: float,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "):\n",
    "    return AttackerGradientReversion(client_data, learning_rate, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackerPartGradientReversion(GradWeightClient):\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # Set random seed for reproducibility\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Call the base implementation to perform the normal training and update process\n",
    "        honest_gradients = super().update(weights, seed)\n",
    "\n",
    "        # Flatten the gradients and calculate 10% of the total number of gradient elements\n",
    "        all_gradients = torch.cat([g.flatten() for g in honest_gradients])\n",
    "        num_to_manipulate = int(all_gradients.numel())\n",
    "\n",
    "        # Determine the threshold of parameters to modify\n",
    "        param_threshold = (\n",
    "            num_to_manipulate * 0.00001\n",
    "        )  # Set this to your desired threshold\n",
    "\n",
    "        # Select the first k layers until the cumulative number of parameters exceeds the threshold\n",
    "        cumulative_params = 0\n",
    "        selected_gradients = []\n",
    "        for gradient in honest_gradients:\n",
    "            # print(gradient.numel())\n",
    "            cumulative_params += gradient.numel()\n",
    "            selected_gradients.append(gradient)\n",
    "            if cumulative_params >= param_threshold:\n",
    "                break\n",
    "\n",
    "        # Multiply the selected gradients by -1000\n",
    "        for gradient in selected_gradients:\n",
    "            gradient *= -1000\n",
    "\n",
    "        return honest_gradients  # Return the modified gradients\n",
    "\n",
    "\n",
    "def build_partial_gradient_reversion_client(\n",
    "    client_data: torch.utils.data.Dataset[typing.Any],\n",
    "    learning_rate: float,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "):\n",
    "    return AttackerPartGradientReversion(client_data, learning_rate, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new data class that help us to process batch\n",
    "@dataclass\n",
    "class Batch:\n",
    "    batch_id: int\n",
    "    inputs: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.batch_size = self.inputs.shape[0]\n",
    "\n",
    "    def to(self, device):\n",
    "        inputs = self.inputs.to(device)\n",
    "        labels = self.labels.to(device)\n",
    "        return Batch(self.batch_id, inputs, labels)\n",
    "\n",
    "    def clone(self):\n",
    "        inputs = self.inputs.clone()\n",
    "        labels = self.labels.clone()\n",
    "        return Batch(self.batch_id, inputs, labels)\n",
    "\n",
    "    def clip(self, batch_size):\n",
    "        if batch_size is None:\n",
    "            return self\n",
    "\n",
    "        inputs = self.inputs[:batch_size]\n",
    "        labels = self.labels[:batch_size]\n",
    "\n",
    "        return Batch(self.batch_id, inputs, labels)\n",
    "\n",
    "\n",
    "class Synthesizer:\n",
    "    def __init__(self, poisoning_proportion):\n",
    "        self.poisoning_proportion = poisoning_proportion\n",
    "\n",
    "    def make_backdoor_batch(self, batch: Batch, test=False, attack=True) -> Batch:\n",
    "        if not attack:\n",
    "            return batch\n",
    "\n",
    "        if test:\n",
    "            attack_portion = batch.batch_size\n",
    "        else:\n",
    "            attack_portion = round(batch.batch_size * self.poisoning_proportion)\n",
    "\n",
    "        backdoored_batch = batch.clone()\n",
    "        self.apply_backdoor(backdoored_batch, attack_portion)\n",
    "        return backdoored_batch\n",
    "\n",
    "    def apply_backdoor(self, batch, attack_portion):\n",
    "        \"\"\"\n",
    "        Modifies only a portion of the batch (represents batch poisoning).\n",
    "\n",
    "        :param batch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.synthesize_inputs(batch=batch, attack_portion=attack_portion)\n",
    "        self.synthesize_labels(batch=batch, attack_portion=attack_portion)\n",
    "\n",
    "        return\n",
    "\n",
    "    def synthesize_inputs(self, batch, attack_portion=None) -> None:\n",
    "        raise NotImplemented\n",
    "\n",
    "    def synthesize_labels(self, batch, attack_portion=None) -> None:\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "class PatternSynthesizer(Synthesizer):\n",
    "    pattern_tensor: torch.Tensor = torch.tensor(\n",
    "        [\n",
    "            [1.0, 0.0, 1.0],\n",
    "            [-10.0, 1.0, -10.0],\n",
    "            [-10.0, -10.0, 0.0],\n",
    "            [-10.0, 1.0, -10.0],\n",
    "            [1.0, 0.0, 1.0],\n",
    "        ]\n",
    "    )\n",
    "    \"Just some random 2D pattern.\"\n",
    "\n",
    "    x_top = 3\n",
    "    \"X coordinate to put the backdoor into.\"\n",
    "    y_top = 23\n",
    "    \"Y coordinate to put the backdoor into.\"\n",
    "\n",
    "    mask_value = -10\n",
    "    \"A tensor coordinate with this value won't be applied to the image.\"\n",
    "\n",
    "    resize_scale = (5, 10)\n",
    "    \"If the pattern is dynamically placed, resize the pattern.\"\n",
    "\n",
    "    mask: torch.Tensor = None\n",
    "    \"A mask used to combine backdoor pattern with the original image.\"\n",
    "\n",
    "    pattern: torch.Tensor = None\n",
    "    \"A tensor of the `input.shape` filled with `mask_value` except backdoor.\"\n",
    "\n",
    "    def __init__(self, poisoning_proportion):\n",
    "        super().__init__(poisoning_proportion)\n",
    "        self.input_shape = (1, 28, 28)\n",
    "        self.backdoor_label = 0\n",
    "        self.normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "        self.make_pattern(self.pattern_tensor, self.x_top, self.y_top)\n",
    "\n",
    "    def make_pattern(self, pattern_tensor, x_top, y_top):\n",
    "        # put pattern into the image\n",
    "        full_image = torch.zeros(self.input_shape)\n",
    "        full_image.fill_(self.mask_value)\n",
    "        # full image has a pixel value of -10\n",
    "        x_bot = x_top + pattern_tensor.shape[0]\n",
    "        y_bot = y_top + pattern_tensor.shape[1]\n",
    "\n",
    "        if x_bot >= self.input_shape[1] or y_bot >= self.input_shape[2]:\n",
    "            raise ValueError(\n",
    "                f\"Position of backdoor outside image limits:\"\n",
    "                f\"image: {self.input_shape}, but backdoor\"\n",
    "                f\"ends at ({x_bot}, {y_bot})\"\n",
    "            )\n",
    "\n",
    "        full_image[:, x_top:x_bot, y_top:y_bot] = pattern_tensor\n",
    "        # full image has a pixel value of -10 except for the backdoor (pattern_tensor) size: 5 * 3\n",
    "        self.mask = 1 * (full_image != self.mask_value).to(device)  # (0, 1)\n",
    "        # mask is a tensor of 0 and 1, 0 for -10 and 1 for other values\n",
    "        self.pattern = self.normalize(full_image).to(device)  # )(-52.5678, 2.7537)\n",
    "\n",
    "    def synthesize_inputs(self, batch, attack_portion=None):\n",
    "        pattern, mask = self.get_pattern()\n",
    "        # mask value (0, 1); value 0, keep the original image; value 1, replace with pattern\n",
    "        batch.inputs[:attack_portion] = (1 - mask) * batch.inputs[\n",
    "            :attack_portion\n",
    "        ] + mask * pattern\n",
    "\n",
    "        return\n",
    "\n",
    "    def synthesize_labels(self, batch, attack_portion=None):\n",
    "        batch.labels[:attack_portion].fill_(self.backdoor_label)\n",
    "        return\n",
    "\n",
    "    def get_pattern(self):\n",
    "        return self.pattern, self.mask\n",
    "\n",
    "\n",
    "poisoning_proportion = 0.5\n",
    "synthesizer = PatternSynthesizer(poisoning_proportion=poisoning_proportion)\n",
    "\n",
    "\n",
    "class AttackerBackdoor(GradWeightClient):\n",
    "    def train_epoch(\n",
    "        self, model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer\n",
    "    ) -> None:\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(loader):\n",
    "            batch = Batch(batch_idx, inputs, labels)\n",
    "            batch = batch.to(device)\n",
    "            backdoored_batch = synthesizer.make_backdoor_batch(\n",
    "                batch, test=False, attack=True\n",
    "            )\n",
    "            data = backdoored_batch.inputs\n",
    "            target = backdoored_batch.labels\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # Load the server weights into the model\n",
    "        with torch.no_grad():\n",
    "            for client_values, server_values in zip(self.model.parameters(), weights):\n",
    "                client_values[:] = server_values\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Save initial weights to calculate the gradients later\n",
    "        initial_weights = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        for _epoch in range(self.nr_epochs):\n",
    "            self.train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "\n",
    "        # Calculate gradients: final_weights - initial_weights\n",
    "        gradients = [\n",
    "            5 * (initial_weight - final_weight)\n",
    "            for final_weight, initial_weight in zip(\n",
    "                self.model.parameters(), initial_weights\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        return [gradient.detach().cpu().clone() for gradient in gradients]\n",
    "\n",
    "\n",
    "def build_backdoor_client(\n",
    "    client_data: torch.utils.data.Dataset[typing.Any],\n",
    "    learning_rate: float,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "):\n",
    "    return AttackerBackdoor(\n",
    "        client_data=client_data,\n",
    "        lr=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        nr_epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b4403",
   "metadata": {},
   "source": [
    "### defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krum(\n",
    "    clients_updates: list[tuple[int, torch.Tensor]],\n",
    "    total_update_count: int = 20,\n",
    "    max_malicious_update_count: int = 4,\n",
    ") -> list[int]:\n",
    "    nearest_neighbors_count = total_update_count - max_malicious_update_count - 2\n",
    "    scores = []\n",
    "\n",
    "    # Calculate the score for each update\n",
    "    for i in range(len(clients_updates)):\n",
    "        distances = []\n",
    "        for j in range(len(clients_updates)):\n",
    "            if i != j:\n",
    "                # Compute squared l2 distance between updates\n",
    "                distance = sum(\n",
    "                    (param_i - param_j).pow(2).sum()\n",
    "                    for param_i, param_j in zip(\n",
    "                        clients_updates[i][1], clients_updates[j][1]\n",
    "                    )\n",
    "                )\n",
    "                distances.append(distance)\n",
    "\n",
    "        nearest_distances = sorted(distances)[:nearest_neighbors_count]\n",
    "\n",
    "        # Sum of these distances is the score of this client's update\n",
    "        scores.append(sum(nearest_distances))\n",
    "\n",
    "    # Select the index with the smallest score\n",
    "    selected_index = scores.index(min(scores))\n",
    "    return [selected_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(\n",
    "    clients_updates: list[tuple[int, torch.Tensor]],\n",
    "    considered_update_count=14,\n",
    "    total_update_count: int = 20,\n",
    "    max_malicious_update_count: int = 5,\n",
    ") -> list[int]:\n",
    "    selected_indices = []\n",
    "    remaining_updates = clients_updates[:]\n",
    "\n",
    "    for i in range(considered_update_count):\n",
    "        # Apply Krum to the remaining updates and get the index of the best gradient\n",
    "        selected_index = krum(\n",
    "            remaining_updates, total_update_count - i, max_malicious_update_count\n",
    "        )[0]\n",
    "\n",
    "        # Map selected index from remaining_updates back to the original clients_updates\n",
    "        original_index = clients_updates.index(remaining_updates[selected_index])\n",
    "        selected_indices.append(original_index)\n",
    "\n",
    "        # Remove the selected update from remaining_updates\n",
    "        remaining_updates.pop(selected_index)\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains the gradients for all parameters from one client\n",
    "type ClientUpdate = list[torch.Tensor]\n",
    "\n",
    "\n",
    "def trimmed_mean(all_updates: list[ClientUpdate], beta: float = 0.4):\n",
    "    # 'n_attackers' is the number of top and bottom values to exclude from the mean calculation.\n",
    "\n",
    "    # Transpose the list to group gradients of the same parameter together\n",
    "    parameter_wise_updates = list(zip(*all_updates))\n",
    "    n_attackers = int(20 * beta)\n",
    "    trimmed_mean_gradients = []\n",
    "    for parameter_group in parameter_wise_updates:\n",
    "        # Stack gradients to create a new dimension corresponding to clients\n",
    "        stacked_updates = torch.stack(parameter_group, dim=0)\n",
    "\n",
    "        # Sort updates along the client dimension\n",
    "        sorted_updates = torch.sort(stacked_updates, dim=0)[0]\n",
    "        # Compute mean excluding the top and bottom 'n_attackers' updates\n",
    "        if n_attackers > 0:\n",
    "            trimmed_updates = sorted_updates[n_attackers:-n_attackers]\n",
    "        else:\n",
    "            trimmed_updates = sorted_updates\n",
    "\n",
    "        mean_gradient = torch.mean(trimmed_updates, dim=0)\n",
    "        trimmed_mean_gradients.append(mean_gradient * 20)\n",
    "\n",
    "    return trimmed_mean_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_sign_filter(all_updates: list[ClientUpdate]) -> list[torch.Tensor]:\n",
    "    # Step 1: Transpose the list to group gradients of the same parameter together\n",
    "    parameter_wise_updates = list(zip(*all_updates))\n",
    "\n",
    "    # Step 2: Calculate sign and count for determining majority\n",
    "    all_signs = [\n",
    "        torch.sign(torch.stack(parameter_group, dim=0))\n",
    "        for parameter_group in parameter_wise_updates\n",
    "    ]\n",
    "\n",
    "    # Step 3: Determine the majority sign for each parameter coordinate\n",
    "    majority_signs = [torch.sign(torch.sum(signs, dim=0)) for signs in all_signs]\n",
    "\n",
    "    # Step 4: Filter out gradients whose signs don't match the majority\n",
    "    filtered_updates = []\n",
    "    for idx, parameter_group in enumerate(parameter_wise_updates):\n",
    "        majority_sign = majority_signs[idx]\n",
    "        zeroed_gradients = []\n",
    "\n",
    "        for gradient in parameter_group:\n",
    "            gradient_signs = torch.sign(gradient)\n",
    "            # Zero out gradients where the sign does not match the majority\n",
    "            gradient[gradient_signs != majority_sign] = 0\n",
    "            zeroed_gradients.append(gradient)\n",
    "\n",
    "        # Step 5: Calculate the average of the filtered gradients\n",
    "        filtered_average = torch.mean(torch.stack(zeroed_gradients), dim=0)\n",
    "        filtered_updates.append(filtered_average * 20)\n",
    "\n",
    "    return filtered_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipping(\n",
    "    all_updates: list[ClientUpdate],\n",
    "    clip_norm_ratio: float = 1.0,\n",
    "    noise_std_dev: float = 0.01,\n",
    ") -> list[torch.Tensor]:\n",
    "    # 'all_updates' is a list of lists of torch.Tensor objects,\n",
    "    # where each inner list contains the gradients for all parameters from one client.\n",
    "\n",
    "    # Step 1: Calculate the norm of each client's update\n",
    "    norms = [\n",
    "        torch.norm(torch.stack([torch.norm(p) for p in client_update]))\n",
    "        for client_update in all_updates\n",
    "    ]\n",
    "    average_norm = sum(norms) / len(norms) * clip_norm_ratio\n",
    "\n",
    "    # Step 2: Clip each client's update\n",
    "    clipped_updates = []\n",
    "    for client_update in all_updates:\n",
    "        clipped_update = []\n",
    "        client_norm = torch.norm(torch.stack([torch.norm(p) for p in client_update]))\n",
    "        clip_scale = min(\n",
    "            1, average_norm / (client_norm + 1e-6)\n",
    "        )  # Avoid division by zero\n",
    "\n",
    "        for gradient in client_update:\n",
    "            clipped_gradient = gradient * clip_scale\n",
    "\n",
    "            clipped_update.append(clipped_gradient)\n",
    "\n",
    "        clipped_updates.append(clipped_update)\n",
    "\n",
    "    # Step 4: Compute the average of these modified gradients\n",
    "    parameter_wise_updates = list(zip(*clipped_updates))\n",
    "\n",
    "    # TODO: Wouldn't this be equivalent to summing up?\n",
    "    averaged_gradients = [\n",
    "        torch.mean(torch.stack(parameter_group), dim=0) * 20\n",
    "        for parameter_group in parameter_wise_updates\n",
    "    ]\n",
    "\n",
    "    return averaged_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ee01b",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BackdoorEvaluationResult:\n",
    "    accuracy: float\n",
    "    success_rate: float\n",
    "    confusion_matrix: np.ndarray\n",
    "\n",
    "\n",
    "def evaluate_backdoor(\n",
    "    model, test_loader: DataLoader, classes_count: int = 10\n",
    ") -> BackdoorEvaluationResult:\n",
    "    dataset_size = 0\n",
    "    correct = 0\n",
    "    successful_attacks = 0\n",
    "\n",
    "    confusion_matrix = np.zeros((classes_count, classes_count), dtype=np.int16)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            batch = Batch(batch_idx, inputs, labels)\n",
    "            batch = batch.to(device)\n",
    "            backdoored_batch = synthesizer.make_backdoor_batch(\n",
    "                batch, test=True, attack=True\n",
    "            )\n",
    "\n",
    "            batch_data = backdoored_batch.inputs\n",
    "            batch_target = backdoored_batch.labels\n",
    "\n",
    "            batch_output = model(batch_data)\n",
    "            batch_predictions = batch_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            dataset_size += batch_data.shape[0]\n",
    "            correct += (\n",
    "                batch_predictions.eq(batch.labels.view_as(batch_predictions))\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "            successful_attacks += (\n",
    "                batch_predictions.eq(batch_target.view_as(batch_predictions))\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "            # Update confusion matrix\n",
    "            for target_value, predicted_value in zip(\n",
    "                batch.labels.view(-1), batch_predictions.view(-1)\n",
    "            ):\n",
    "                confusion_matrix[target_value.long(), predicted_value.long()] += 1\n",
    "\n",
    "    accuracy = 100.0 * correct / dataset_size\n",
    "    success_rate = 100.0 * successful_attacks / dataset_size\n",
    "\n",
    "    return BackdoorEvaluationResult(\n",
    "        accuracy=accuracy, success_rate=success_rate, confusion_matrix=confusion_matrix\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix: np.ndarray):\n",
    "    class_names = [str(it) for it in range(10)]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(\n",
    "        confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257d814",
   "metadata": {},
   "source": [
    "## Question 1: Influence of Non-I.I.D. Data in Attacks and Defenses (4 points)\n",
    "\n",
    "Using the template code from the overview notebook ([src](./overview.ipynb)), experiment with how non-i.i.d. data distributions influence the performance of attacks and defenses. Utilize the `AttackerGradientReversion` for the attack. Keep all hyperparameters the same as those in the template code, except modify the data distribution among the clients to be non-i.i.d.\n",
    "\n",
    "### Scoring:\n",
    "\n",
    "- _(1 point)_ Generate test accuracy for 10 rounds, both when there is no defense and when the defenses are `krum`, `multi_krum`, and `majority_sign`. \n",
    "- _(1 point)_ Compile the results of these runs into one plot to visually compare the influence of each defense mechanism under non-i.i.d. conditions.\n",
    "- _(2 points)_ Discuss the differences (if any) between the results in i.i.d. and non-i.i.d. settings for each defense mechanism. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83726ab5",
   "metadata": {},
   "source": [
    "### implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServerDefense(FedAvgGradServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        client_subsets: list,\n",
    "        client_fraction: float,\n",
    "        nr_local_epochs: int,\n",
    "        seed: int,\n",
    "        defense=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            lr, batch_size, client_subsets, client_fraction, nr_local_epochs, seed\n",
    "        )\n",
    "        self.defense_method = defense\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # The beginning of the method remains unchanged\n",
    "        elapsed_time = 0.0\n",
    "        run_result = RunResult(\n",
    "            self.name,\n",
    "            self.nr_clients,\n",
    "            self.client_fraction,\n",
    "            self.batch_size,\n",
    "            self.nr_local_epochs,\n",
    "            self.lr,\n",
    "            self.seed,\n",
    "        )\n",
    "\n",
    "        # Initial server weights\n",
    "        server_weights = [param.data.clone() for param in self.model.parameters()]\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False\n",
    "            )\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients\n",
    "            )\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.0\n",
    "\n",
    "            client_updates = []  # Store (client_index, updates) tuples\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = (\n",
    "                    self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                )\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                client_updates.append((ind, client_weights))\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "            if self.defense_method:\n",
    "                selected_indices = self.defense_method(client_updates)\n",
    "            else:\n",
    "                selected_indices = range(\n",
    "                    len(client_updates)\n",
    "                )  # Use all updates if no defense is specified\n",
    "\n",
    "            self._print_selected_clients(indices_chosen_clients[selected_indices].tolist())\n",
    "\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i]\n",
    "                for i in indices_chosen_clients[selected_indices]\n",
    "            )\n",
    "            chosen_adjusted_weights = [\n",
    "                [\n",
    "                    self.client_sample_counts[indices_chosen_clients[ind]]\n",
    "                    / chosen_sum_nr_samples\n",
    "                    * tens\n",
    "                    for tens in client_updates[ind][1]\n",
    "                ]\n",
    "                for ind in selected_indices\n",
    "            ]\n",
    "            # Aggregation logic remains the same from this point onwards\n",
    "            # Note that chosen_adjusted_weights now only contains updates from clients selected by multi_krum\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            averaged_gradients: list[torch.Tensor] = [\n",
    "                sum(x) for x in zip(*chosen_adjusted_weights)\n",
    "            ]\n",
    "\n",
    "            # Update server model with averaged gradients\n",
    "            with torch.no_grad():\n",
    "                for server_weight, gradient in zip(server_weights, averaged_gradients):\n",
    "                    server_weight -= gradient.to(\n",
    "                        device=device\n",
    "                    )  # Assume learning rate is absorbed in gradient\n",
    "\n",
    "            # Distribute updated weights to clients\n",
    "            with torch.no_grad():\n",
    "                for param, server_weight in zip(\n",
    "                    self.model.parameters(), server_weights\n",
    "                ):\n",
    "                    param.data[:] = server_weight.data\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(\n",
    "                2 * (nr_round + 1) * self.nr_clients_per_round\n",
    "            )\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result\n",
    "\n",
    "    def _print_selected_clients(self, client_indices: typing.Iterable[int]) -> None:\n",
    "        ordered_indices = list(sorted(client_indices))\n",
    "        malicious_indices = list(\n",
    "            filter(lambda idx: not is_client_benign(self.clients[idx]), ordered_indices)\n",
    "        )\n",
    "\n",
    "        print(f\"selected clients: {ordered_indices} (whereof {len(malicious_indices) } are malicious)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServerDefenseCoordinate(FedAvgGradServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        client_subsets: list,\n",
    "        client_fraction: float,\n",
    "        nr_local_epochs: int,\n",
    "        seed: int,\n",
    "        defense=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            lr, batch_size, client_subsets, client_fraction, nr_local_epochs, seed\n",
    "        )\n",
    "        self.defense_method = defense\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # The beginning of the method remains unchanged\n",
    "        elapsed_time = 0.0\n",
    "        run_result = RunResult(\n",
    "            self.name,\n",
    "            self.nr_clients,\n",
    "            self.client_fraction,\n",
    "            self.batch_size,\n",
    "            self.nr_local_epochs,\n",
    "            self.lr,\n",
    "            self.seed,\n",
    "        )\n",
    "\n",
    "        # Initial server weights\n",
    "        server_weights = [param.data.clone() for param in self.model.parameters()]\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self.rng.choice(\n",
    "                self.nr_clients, self.nr_clients_per_round, replace=False\n",
    "            )\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i] for i in indices_chosen_clients\n",
    "            )\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = []\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "            update_time = 0.0\n",
    "\n",
    "            for c_i in indices_chosen_clients:\n",
    "                update_start_time = perf_counter()\n",
    "                ind = int(c_i)\n",
    "                client_round_seed = (\n",
    "                    self.seed + ind + 1 + nr_round * self.nr_clients_per_round\n",
    "                )\n",
    "                client_weights = self.clients[ind].update(weights, client_round_seed)\n",
    "                chosen_adjusted_weights.append(\n",
    "                    [\n",
    "                        self.client_sample_counts[ind] / chosen_sum_nr_samples * tens\n",
    "                        for tens in client_weights\n",
    "                    ]\n",
    "                )\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "            if self.defense_method:\n",
    "                averaged_gradients = self.defense_method(chosen_adjusted_weights)\n",
    "            else:\n",
    "                averaged_gradients: list[torch.Tensor] = [\n",
    "                    sum(x) for x in zip(*chosen_adjusted_weights)\n",
    "                ]\n",
    "\n",
    "            # Update server model with averaged gradients\n",
    "            with torch.no_grad():\n",
    "                for server_weight, gradient in zip(server_weights, averaged_gradients):\n",
    "                    server_weight -= gradient.to(\n",
    "                        device=device\n",
    "                    )  # Assume learning rate is absorbed in gradient\n",
    "\n",
    "            # Distribute updated weights to clients\n",
    "            with torch.no_grad():\n",
    "                for param, server_weight in zip(\n",
    "                    self.model.parameters(), server_weights\n",
    "                ):\n",
    "                    param.data[:] = server_weight.data\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(\n",
    "                2 * (nr_round + 1) * self.nr_clients_per_round\n",
    "            )\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f35aa",
   "metadata": {},
   "source": [
    "### establish baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = split(nr_clients=100, iid=True, seed=42)\n",
    "FedAvgServerDefense(0.02, 200, dataset, 0.2, 2, 42, None).run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10952072",
   "metadata": {},
   "source": [
    "### benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4786e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type _ClientFactory = typing.Callable[\n",
    "    [torch.utils.data.Dataset[typing.Any], float, int, int], Client\n",
    "]\n",
    "\n",
    "\n",
    "def inject_malicious_clients(\n",
    "    server: Server,\n",
    "    malicious_client_factory: _ClientFactory,\n",
    "):\n",
    "    clients = server.clients\n",
    "\n",
    "    # Number of clients to be made malicious with gradient reversion\n",
    "    num_malicious = int(0.20 * len(clients))  # For example, 20%\n",
    "\n",
    "    # Randomly select indices for the clients to undergo gradient inversion attack\n",
    "    generator = np.random.default_rng(43)\n",
    "    malicious_indices = generator.choice(len(clients), num_malicious, replace=False)\n",
    "\n",
    "    # Replace the selected clients with instances of AttackerGradientInversion\n",
    "    print(f\"injected malicious clients at indices: {np.sort(malicious_indices)}\")\n",
    "\n",
    "    for idx in malicious_indices:\n",
    "        client_data = clients[idx].loader_train.dataset\n",
    "        lr = clients[idx].optimizer.param_groups[0][\"lr\"]\n",
    "        batch_size = clients[idx].loader_train.batch_size\n",
    "        nr_epochs = clients[idx].nr_epochs\n",
    "\n",
    "        clients[idx] = malicious_client_factory(client_data, lr, batch_size, nr_epochs)\n",
    "\n",
    "\n",
    "def configure_server_index(dataset: SplitDataset, defense: typing.Any) -> Server:\n",
    "    server = FedAvgServerDefense(\n",
    "        lr=0.02,\n",
    "        batch_size=200,\n",
    "        client_subsets=dataset,\n",
    "        client_fraction=0.2,\n",
    "        nr_local_epochs=2,\n",
    "        seed=42,\n",
    "        defense=defense,\n",
    "    )\n",
    "\n",
    "    inject_malicious_clients(\n",
    "        server, malicious_client_factory=build_gradient_reversion_client\n",
    "    )\n",
    "    return server\n",
    "\n",
    "\n",
    "def configure_server_parameter(dataset: SplitDataset, defense: typing.Any) -> Server:\n",
    "    server = FedAvgServerDefenseCoordinate(\n",
    "        lr=0.02,\n",
    "        batch_size=200,\n",
    "        client_subsets=dataset,\n",
    "        client_fraction=0.2,\n",
    "        nr_local_epochs=2,\n",
    "        seed=42,\n",
    "        defense=defense,\n",
    "    )\n",
    "\n",
    "    inject_malicious_clients(\n",
    "        server, malicious_client_factory=build_gradient_reversion_client\n",
    "    )\n",
    "    return server\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    iid: bool, method: typing.Literal[\"krum\", \"multi-krum\", \"majority-sign\"] | None\n",
    ") -> RunResult:\n",
    "    dataset = split(nr_clients=100, iid=iid, seed=42)\n",
    "\n",
    "    match method:\n",
    "        case \"krum\":\n",
    "            return configure_server_index(dataset=dataset, defense=krum).run(10)\n",
    "        case \"multi-krum\":\n",
    "            return configure_server_index(dataset=dataset, defense=multi_krum).run(10)\n",
    "        case \"majority-sign\":\n",
    "            return configure_server_parameter(dataset=dataset, defense=majority_sign_filter).run(10)\n",
    "        case None:\n",
    "            return configure_server_index(dataset=dataset, defense=None).run(10)\n",
    "            # 77.2, 81.01, 83.13, 85.26, 85.03, 87.22])\n",
    "            #return FedAvgGradServer(0.02, 200, sample_split, 0.2, 2, 42).run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e78ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_mechanism_variants = [\"krum\", \"multi-krum\", \"majority-sign\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_defense_mechanism_iid = [\n",
    "    run_training(iid=True, method=method)\n",
    "    for method in tqdm(defense_mechanism_variants, \"defense mechanism\", leave=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2852c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_defense_mechanism_non_iid = [\n",
    "    run_training(iid=False, method=method)\n",
    "    for method in tqdm(defense_mechanism_variants, \"defense mechanism\", leave=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_defense_mechanism_iid[2].as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893646ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"test accuracy\")\n",
    "for statistics, variant_name in zip(results_defense_mechanism_iid, defense_mechanism_variants):\n",
    "    plt.plot(statistics.test_accuracy, label=f\"{variant_name}\", alpha=0.7)\n",
    "plt.legend()\n",
    "# plt.ylim(None, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"test accuracy\")\n",
    "for statistics, variant_name in zip(results_defense_mechanism_non_iid, defense_mechanism_variants):\n",
    "    plt.plot(statistics.test_accuracy, label=f\"{variant_name}\", alpha=0.7)\n",
    "plt.legend()\n",
    "# plt.ylim(None, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dec38",
   "metadata": {},
   "source": [
    "## Question 2: Implementing Bulyan Defense (5 points)\n",
    "\n",
    "[Bulyan defense](https://arxiv.org/abs/1802.07927) combines aspects of `multi-krum` and `trimmed-mean` to protect against sophisticated attacks in federated environments. In this question, you will implement Bulyan by modifying and combining the existing code in the [attacks_and_defenses.ipynb](https://github.com/lydiaYchen/DDL25Spring/blob/main/lab/tutorial_3/attacks_and_defenses.ipynb).\n",
    "\n",
    "### Scoring:\n",
    "- _(1 point)_ Modify the server-side code to integrate a two-step defense process where:\n",
    "  1. A client-wise defense like `multi-krum` filters out suspicious gradients based on their distance metrics.\n",
    "  2. A coordinate-wise defense like `trimmed-mean` calculates the mean across the remaining gradients after trimming the extremes.\n",
    "  \n",
    "- _(1 point)_ Successfully integrate these two defense mechanisms [`multi-krum`, `trimmed-mean`] to implement the Bulyan.\n",
    "- _(3 points)_ Evaluate the performance of your implemented Bulyan defense against three types of attacks: `AttackerGradientReversion`, `AttackerPartGradientReversion`, and `AttackerBackdoor`. Vary the defense hyperparameters to make your defense defend against these attacks while keeping the data distribution i.i.d. and the attacker's hyperparameters constant as per the template. Document the performance of your defense strategy against these attacks in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedServerDefense(FedAvgGradServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        client_subsets: list,\n",
    "        client_fraction: float,\n",
    "        nr_local_epochs: int,\n",
    "        seed: int,\n",
    "        defense_client_wise=None,\n",
    "        defense_coordinate_wise=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            lr, batch_size, client_subsets, client_fraction, nr_local_epochs, seed\n",
    "        )\n",
    "        self._defense_client_wise = defense_client_wise\n",
    "        self._defense_coordinate_wise = defense_coordinate_wise\n",
    "\n",
    "    def _sample_clients(self):\n",
    "        return self.rng.choice(\n",
    "            self.nr_clients, self.nr_clients_per_round, replace=False\n",
    "        )\n",
    "\n",
    "    def _print_selected_clients(self, client_indices: typing.Iterable[int]) -> None:\n",
    "        ordered_indices = list(sorted(client_indices))\n",
    "        malicious_indices = list(\n",
    "            filter(lambda idx: not is_client_benign(self.clients[idx]), ordered_indices)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"selected clients: {ordered_indices} (whereof {len(malicious_indices) } are malicious)\"\n",
    "        )\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # The beginning of the method remains unchanged\n",
    "        elapsed_time = 0.0\n",
    "        run_result = RunResult(\n",
    "            self.name,\n",
    "            self.nr_clients,\n",
    "            self.client_fraction,\n",
    "            self.batch_size,\n",
    "            self.nr_local_epochs,\n",
    "            self.lr,\n",
    "            self.seed,\n",
    "        )\n",
    "\n",
    "        # Initial server weights\n",
    "        server_weights = [param.data.clone() for param in self.model.parameters()]\n",
    "        for nr_round in tqdm(range(nr_rounds), desc=\"Rounds\", leave=False):\n",
    "            setup_start_time = perf_counter()\n",
    "            self.model.train()\n",
    "            weights = [x.detach().cpu().clone() for x in self.model.parameters()]\n",
    "            indices_chosen_clients = self._sample_clients()\n",
    "            elapsed_time += perf_counter() - setup_start_time\n",
    "\n",
    "            update_time = 0.0\n",
    "            client_updates: list[tuple[int, ClientUpdate]] = []\n",
    "            for client_idx in indices_chosen_clients.tolist():\n",
    "                update_start_time = perf_counter()\n",
    "\n",
    "                client_round_seed = (\n",
    "                    self.seed + client_idx + 1 + nr_round * self.nr_clients_per_round\n",
    "                )\n",
    "                client_weights = self.clients[client_idx].update(\n",
    "                    weights, client_round_seed\n",
    "                )\n",
    "                client_updates.append((client_idx, client_weights))\n",
    "\n",
    "                update_time = max(update_time, perf_counter() - update_start_time)\n",
    "\n",
    "            if self._defense_client_wise is not None:\n",
    "                selected_indices = self._defense_client_wise(client_updates)\n",
    "            else:\n",
    "                # Use all updates if no defense is specified\n",
    "                selected_indices = range(len(client_updates))\n",
    "\n",
    "            self._print_selected_clients(indices_chosen_clients[selected_indices].tolist())\n",
    "\n",
    "            chosen_sum_nr_samples = sum(\n",
    "                self.client_sample_counts[i]\n",
    "                for i in indices_chosen_clients[selected_indices]\n",
    "            )\n",
    "            chosen_adjusted_weights: list[list[torch.Tensor]] = [\n",
    "                [\n",
    "                    self.client_sample_counts[indices_chosen_clients[ind]]\n",
    "                    / chosen_sum_nr_samples\n",
    "                    * tens\n",
    "                    for tens in client_updates[ind][1]\n",
    "                ]\n",
    "                for ind in selected_indices\n",
    "            ]\n",
    "\n",
    "            averaged_gradients: list[torch.Tensor]\n",
    "            if self._defense_coordinate_wise is not None:\n",
    "                averaged_gradients = self._defense_coordinate_wise(chosen_adjusted_weights)\n",
    "            else:\n",
    "                # Use torch function for summing up\n",
    "                averaged_gradients = [sum(x) for x in zip(*chosen_adjusted_weights)]\n",
    "\n",
    "            # Aggregation logic remains the same from this point onwards\n",
    "            # Note that chosen_adjusted_weights now only contains updates from clients selected by multi_krum\n",
    "            elapsed_time += update_time\n",
    "            aggregate_start_time = perf_counter()\n",
    "\n",
    "            # Update server model with averaged gradients\n",
    "            with torch.no_grad():\n",
    "                for server_weight, gradient in zip(server_weights, averaged_gradients):\n",
    "                    server_weight -= gradient.to(\n",
    "                        device=device\n",
    "                    )  # Assume learning rate is absorbed in gradient\n",
    "\n",
    "            # Distribute updated weights to clients\n",
    "            with torch.no_grad():\n",
    "                for param, server_weight in zip(\n",
    "                    self.model.parameters(), server_weights\n",
    "                ):\n",
    "                    param.data[:] = server_weight.data\n",
    "\n",
    "            elapsed_time += perf_counter() - aggregate_start_time\n",
    "            run_result.wall_time.append(round(elapsed_time, 1))\n",
    "            run_result.message_count.append(\n",
    "                2 * (nr_round + 1) * self.nr_clients_per_round\n",
    "            )\n",
    "            run_result.test_accuracy.append(self.test())\n",
    "\n",
    "        return run_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_server(\n",
    "    dataset: SplitDataset,\n",
    "    defense_client_wise: typing.Any,\n",
    "    defense_coordinate_wise: typing.Any,\n",
    ") -> Server:\n",
    "    server = CombinedServerDefense(\n",
    "        lr=0.02,\n",
    "        batch_size=200,\n",
    "        client_subsets=dataset,\n",
    "        client_fraction=0.2,\n",
    "        nr_local_epochs=2,\n",
    "        seed=42,\n",
    "        defense_client_wise=defense_client_wise,\n",
    "        defense_coordinate_wise=defense_coordinate_wise,\n",
    "    )\n",
    "\n",
    "    return server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfe842",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BulyanParameters:\n",
    "    krum_considered_update_count: int\n",
    "    krum_max_malicious_update_count: int\n",
    "    mean_beta: float\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    attack_type: typing.Literal[\n",
    "        \"gradient-reversion\", \"partial-gradient-reversion\", \"backdoor\"\n",
    "    ],\n",
    "    parameters: BulyanParameters,\n",
    ") -> tuple[RunResult, BackdoorEvaluationResult]:\n",
    "    dataset = split(nr_clients=100, iid=True, seed=42)\n",
    "\n",
    "    server = configure_server(\n",
    "        dataset,\n",
    "        lambda client_updates: multi_krum(\n",
    "            client_updates,\n",
    "            considered_update_count=parameters.krum_considered_update_count,\n",
    "            total_update_count=20,\n",
    "            max_malicious_update_count=parameters.krum_max_malicious_update_count,\n",
    "        ),\n",
    "        lambda all_updates: trimmed_mean(all_updates, beta=parameters.mean_beta),\n",
    "    )\n",
    "\n",
    "    match attack_type:\n",
    "        case \"gradient-reversion\":\n",
    "            inject_malicious_clients(\n",
    "                server, malicious_client_factory=build_gradient_reversion_client\n",
    "            )\n",
    "        case \"partial-gradient-reversion\":\n",
    "            inject_malicious_clients(\n",
    "                server, malicious_client_factory=build_partial_gradient_reversion_client\n",
    "            )\n",
    "        case 'backdoor':\n",
    "            inject_malicious_clients(server, malicious_client_factory=build_backdoor_client)\n",
    "\n",
    "    return server.run(10), evaluate_backdoor(server.model, test_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_bulyan = [\n",
    "    BulyanParameters(14, 5, 0.1),\n",
    "    BulyanParameters(14, 5, 0.2),\n",
    "    BulyanParameters(14, 5, 0.4),\n",
    "    BulyanParameters(14, 5, 0.6),\n",
    "    BulyanParameters(7, 5, 0.1),\n",
    "    BulyanParameters(7, 5, 0.2),\n",
    "    BulyanParameters(7, 5, 0.4),\n",
    "    BulyanParameters(7, 5, 0.6),\n",
    "    BulyanParameters(14, 2, 0.2),\n",
    "    BulyanParameters(14, 2, 0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764217bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bulyan: list[RunResult] = []\n",
    "results_backdoor_bulyan: list[BackdoorEvaluationResult] = []\n",
    "\n",
    "for variant in tqdm(variants_bulyan, \"variant\", leave=False):\n",
    "    result, backdoor_result = run_training('backdoor', variant)\n",
    "\n",
    "    results_bulyan.append(result)\n",
    "    results_backdoor_bulyan.append(backdoor_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18accb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bulyan_reversion: list[RunResult] = []\n",
    "\n",
    "for variant in tqdm(variants_bulyan, \"variant\", leave=False):\n",
    "    result, _ = run_training('gradient-reversion', variant)\n",
    "\n",
    "    results_bulyan_reversion.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27878b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bulyan_partial_reversion: list[RunResult] = []\n",
    "\n",
    "for variant in tqdm(variants_bulyan, \"variant\", leave=False):\n",
    "    result, _ = run_training('partial-gradient-reversion', variant)\n",
    "\n",
    "    results_bulyan_partial_reversion.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f168b",
   "metadata": {},
   "source": [
    "## Question 3: Implementing SparseFed Defense (7 points)\n",
    "\n",
    "In this exercise, you will implement the [SparseFed Defense](https://arxiv.org/abs/2112.06274). SparseFed Defense involves two main steps for each participating device during the training process:\n",
    "1. **Clipping the gradient:** Each device clips its gradient to reduce the impact of potentially malicious updates.\n",
    "2. **Aggregating top-k updates:** During the aggregation phase, only the gradients with the highest magnitudes (top-k) are considered. This method is designed to minimize the risk of model poisoning by excluding anomalous gradient contributions from potentially compromised devices.\n",
    "\n",
    "### Scoring:\n",
    "- _(2 points)_ Implement a simplified version of SparseFed based on the clipping code provided in the template notebook. Unlike the original algorithm which includes momentum, you only need to implement the clipping step and the sparsification step. However, ensure that only the top-k coordinates in the aggregated gradients are selected based on their magnitudes. For example, if the aggregated gradient is `[3, -1, -1, -3]`, selecting the top-2 by magnitude should result in `[3, 0, 0, -3]`.\n",
    "\n",
    "- _(3 points)_ Evaluate the performance of your implemented SparseFed defense against two types of attacks: `AttackerGradientReversion` and `AttackerBackdoor`. Adjust the values of the defense hyperparameter k to optimize defense effectiveness. Ensure the data distribution remains i.i.d., and the attacker's hyperparameters are unchanged from the template. Document and compare the performance of SparseFed to the simple clipping defense across these attack scenarios. Suggested values for k include percentages of the total parameters, such as 20%, 50%, and 80%.\n",
    "\n",
    "- _(2 points)_ Analyze and discuss the results to determine if SparseFed provided any improvements. Explain why the sparsefication either succeeded or failed in enhancing the model's robustness against the specified attacks. Include this analysis in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_fed(\n",
    "    all_updates: list[ClientUpdate], k: float, clip_norm_ratio: float = 1\n",
    ") -> list[torch.Tensor]:\n",
    "    clipped_parameters: list[torch.Tensor] = clipping(all_updates, clip_norm_ratio)\n",
    "\n",
    "    def sparsify_parameter(parameter: torch.Tensor) -> torch.Tensor:\n",
    "        parameter_shape = parameter.size()\n",
    "        flattened_parameter = parameter.view(-1)\n",
    "\n",
    "        retained_components_count = int(flattened_parameter.size(dim=0) * k)\n",
    "        retained_components = torch.topk(flattened_parameter.abs(), k=retained_components_count)\n",
    "\n",
    "        sparse_parameter = torch.zeros_like(flattened_parameter)\n",
    "        sparse_parameter[retained_components.indices] = flattened_parameter[retained_components.indices]\n",
    "\n",
    "        return sparse_parameter.view(*parameter_shape)\n",
    "\n",
    "    return [sparsify_parameter(it) for it in clipped_parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b984a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    attack_type: typing.Literal[\"gradient-reversion\", \"backdoor\"],\n",
    "    defense_type: typing.Literal[\"clipping\", \"sparse-fed\"],\n",
    "    k: float,\n",
    ") -> tuple[RunResult, BackdoorEvaluationResult]:\n",
    "    dataset = split(nr_clients=100, iid=True, seed=42)\n",
    "\n",
    "    match defense_type:\n",
    "        case \"clipping\":\n",
    "            defense = lambda all_updates: clipping(all_updates)\n",
    "        case \"sparse-fed\":\n",
    "            defense = lambda all_updates: sparse_fed(all_updates, k)\n",
    "\n",
    "    server = configure_server(\n",
    "        dataset,\n",
    "        None,\n",
    "        defense,\n",
    "    )\n",
    "\n",
    "    match attack_type:\n",
    "        case \"gradient-reversion\":\n",
    "            inject_malicious_clients(\n",
    "                server, malicious_client_factory=build_gradient_reversion_client\n",
    "            )\n",
    "        case \"backdoor\":\n",
    "            inject_malicious_clients(\n",
    "                server, malicious_client_factory=build_backdoor_client\n",
    "            )\n",
    "\n",
    "    return server.run(10), evaluate_backdoor(server.model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_sparse_fed = [0.2, 0.5, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13574455",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_clipping, _ = run_training('backdoor', 'clipping', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sparse_fed: list[RunResult] = []\n",
    "results_backdoor_sparse_fed: list[BackdoorEvaluationResult] = []\n",
    "\n",
    "for variant in tqdm(variants_sparse_fed, \"variant\", leave=False):\n",
    "    result, backdoor_result = run_training('backdoor', 'sparse-fed', variant)\n",
    "\n",
    "    results_sparse_fed.append(result)\n",
    "    results_backdoor_sparse_fed.append(backdoor_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_clipping_reversion, _ = run_training('gradient-reversion', 'clipping', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23072163",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sparse_fed_reversion: list[RunResult] = []\n",
    "\n",
    "for variant in tqdm(variants_sparse_fed, \"variant\", leave=False):\n",
    "    result, _ = run_training('gradient-reversion', 'sparse-fed', variant)\n",
    "\n",
    "    results_sparse_fed_reversion.append(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
