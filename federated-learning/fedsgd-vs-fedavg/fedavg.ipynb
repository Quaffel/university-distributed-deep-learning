{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using accelerator 'mps'\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import torch\n",
    "from components.metrics import RunMetrics, RunResult\n",
    "from components.tensor_types import IndexVector\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_path = \"../../datasets\"\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(f\"Using accelerator '{device}'\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARN: No accelerator found, running on CPU\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalize by mean and standard devia,\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    batch_size=10000,\n",
    "    generator=torch.Generator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc1 = torch.nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Log softmax rather than softmax due to negative log likelihood loss.\n",
    "        # log_softmax rather than two separate operations for numerical stability\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.client import AbstractClient\n",
    "\n",
    "\n",
    "# negative log likelihood loss\n",
    "loss_function = torch.nn.functional.nll_loss\n",
    "\n",
    "\n",
    "class WeightClient(AbstractClient):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        client_data: Subset,\n",
    "        learning_rate: float,\n",
    "        batch_size: int,\n",
    "        local_epochs: int,\n",
    "    ) -> None:\n",
    "        super().__init__(model, client_data, batch_size)\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            params=self.model.parameters(), lr=learning_rate\n",
    "        )\n",
    "        self.local_epochs = local_epochs\n",
    "        self.client_data_size = len(client_data)\n",
    "\n",
    "    def train_epoch(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        self.model.train()\n",
    "\n",
    "        for batch_features, batch_target in self.loader_train:\n",
    "            batch_features = typing.cast(torch.Tensor, batch_features).to(device)\n",
    "            batch_target = typing.cast(torch.Tensor, batch_target).to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            batch_output = self.model(batch_features)\n",
    "\n",
    "            batch_loss = loss_function(batch_output, batch_target)\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        self.generator.manual_seed(seed)\n",
    "        self.build_local_model(weights)\n",
    "\n",
    "        for _ in range(self.local_epochs):\n",
    "            self.train_epoch()\n",
    "\n",
    "        parameter_weights = [\n",
    "            parameter.detach().clone().cpu()\n",
    "            for parameter in self.model.parameters()\n",
    "        ]\n",
    "        return parameter_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from components.server import DecentralizedServer\n",
    "\n",
    "\n",
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        learning_rate: float,\n",
    "        batch_size: int,\n",
    "        client_subsets: list[Subset],\n",
    "        client_fraction: float,\n",
    "        local_epochs: int,\n",
    "        seed: int,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            model,\n",
    "            client_subsets,\n",
    "            client_fraction,\n",
    "            learning_rate,\n",
    "            batch_size,\n",
    "            seed,\n",
    "            device,\n",
    "        )\n",
    "        self.local_epochs_count = local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(model, subset, learning_rate, batch_size, local_epochs)\n",
    "            for subset in client_subsets\n",
    "        ]\n",
    "\n",
    "    def select_clients(self) -> IndexVector:\n",
    "        return self.generator.choice(len(self.clients), self.clients_per_round)\n",
    "\n",
    "    def calculate_weight_fraction_for_client(\n",
    "        self,\n",
    "        client: WeightClient,\n",
    "        weights: list[torch.Tensor],\n",
    "        seed: int,\n",
    "        total_epoch_dataset_size: int,\n",
    "    ) -> list[torch.Tensor]:\n",
    "        client_dataset_size = client.client_data_size\n",
    "\n",
    "        return [\n",
    "            client_dataset_size / total_epoch_dataset_size * parameter_weight\n",
    "            for parameter_weight in client.update(weights, seed)\n",
    "        ]\n",
    "\n",
    "    def run_epoch(self, weights: list[torch.Tensor], epoch: int) -> None:\n",
    "        client_indices = [it.item() for it in self.select_clients()]\n",
    "        client_dataset_size = sum(\n",
    "            self.clients[client_idx].client_data_size for client_idx in client_indices\n",
    "        )\n",
    "\n",
    "        # N x M; N clients with weights for M parameters each\n",
    "        client_weights: list[list[torch.Tensor]] = [\n",
    "            self.calculate_weight_fraction_for_client(\n",
    "                self.clients[client_idx],\n",
    "                weights,\n",
    "                seed=self.parameters.seed\n",
    "                + client_idx\n",
    "                + 1\n",
    "                + epoch * self.clients_per_round,\n",
    "                total_epoch_dataset_size=client_dataset_size,\n",
    "            )\n",
    "            for client_idx in tqdm(client_indices, \"clients\", leave=False)\n",
    "        ]\n",
    "\n",
    "        aggregated_client_weights: list[torch.Tensor] = [\n",
    "            # sum weights parameter-wise; 'parameter_weights' is a tuple that contains one weight vector per client\n",
    "            torch.stack(parameter_weights, dim=0).sum(dim=0)\n",
    "            for parameter_weights in zip(*client_weights)\n",
    "        ]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for parameter, parameter_weight in zip(\n",
    "                self.model.parameters(), aggregated_client_weights\n",
    "            ):\n",
    "                parameter[:] = parameter_weight.to(device)\n",
    "\n",
    "    def run(self, rounds: int) -> RunResult:\n",
    "        metrics = RunMetrics()\n",
    "\n",
    "        for epoch in tqdm(range(rounds), \"epoch\", leave=False):\n",
    "            weights = [\n",
    "                parameter.detach().clone() for parameter in self.model.parameters()\n",
    "            ]\n",
    "\n",
    "            wall_clock_start = time.perf_counter()\n",
    "            weights = self.run_epoch(weights, epoch)\n",
    "            wall_clock_end = time.perf_counter()\n",
    "\n",
    "            accuracy = self.evaluate_accuracy(test_loader)\n",
    "            execution_time_s = wall_clock_end - wall_clock_start\n",
    "\n",
    "            metrics.test_accuracy.append(accuracy)\n",
    "            metrics.wall_time.append(execution_time_s)\n",
    "            metrics.message_count.append(2 * self.clients_per_round * (epoch + 1))\n",
    "\n",
    "        return RunResult(\"FedAvg\", self.parameters, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a123371342443fbb74b6826f18aed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9647f92577e74674873143937b35d333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  2213 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e273527d484ef4b7ff121843d41a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  5637 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89044f2abe48462984e8455dc31f0ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  6777 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248b4faef5ad40a4b767b563bfb2d466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  7428 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188185b5ee0b4adbbfb82a22c0d2c4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  7684 total:  10000\n"
     ]
    }
   ],
   "source": [
    "from components.data_splitting import (\n",
    "    index_uniformly,\n",
    "    partition_dataset,\n",
    ")\n",
    "\n",
    "client_datasets = partition_dataset(\n",
    "    train_dataset,\n",
    "    index_uniformly(\n",
    "        train_dataset, partitions_count=100, generator_or_seed=42\n",
    "    ),\n",
    ")\n",
    "\n",
    "fedavg_server = FedAvgServer(\n",
    "    MnistCnn().to(device),\n",
    "    learning_rate=0.02,\n",
    "    batch_size=200,\n",
    "    client_subsets=client_datasets,\n",
    "    client_fraction=0.2,\n",
    "    local_epochs=2,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "result_fedavg = fedavg_server.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clients_count</th>\n",
       "      <th>active_clients_fraction</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>local_epochs_count</th>\n",
       "      <th>η</th>\n",
       "      <th>seed</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>message_count (sum)</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>3.115875</td>\n",
       "      <td>40</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>3.140193</td>\n",
       "      <td>80</td>\n",
       "      <td>0.5637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>3.133477</td>\n",
       "      <td>120</td>\n",
       "      <td>0.6777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>3.406714</td>\n",
       "      <td>160</td>\n",
       "      <td>0.7428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>3.190974</td>\n",
       "      <td>200</td>\n",
       "      <td>0.7684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round algorithm  clients_count  active_clients_fraction  batch_size  \\\n",
       "0      1    FedAvg            100                      0.2         200   \n",
       "1      2    FedAvg            100                      0.2         200   \n",
       "2      3    FedAvg            100                      0.2         200   \n",
       "3      4    FedAvg            100                      0.2         200   \n",
       "4      5    FedAvg            100                      0.2         200   \n",
       "\n",
       "   local_epochs_count     η  seed  wall_time  message_count (sum)  \\\n",
       "0                   1  0.02    42   3.115875                   40   \n",
       "1                   1  0.02    42   3.140193                   80   \n",
       "2                   1  0.02    42   3.133477                  120   \n",
       "3                   1  0.02    42   3.406714                  160   \n",
       "4                   1  0.02    42   3.190974                  200   \n",
       "\n",
       "   test_accuracy  \n",
       "0         0.2213  \n",
       "1         0.5637  \n",
       "2         0.6777  \n",
       "3         0.7428  \n",
       "4         0.7684  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
