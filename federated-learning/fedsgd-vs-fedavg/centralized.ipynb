{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using accelerator 'mps'\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_path = \"../../datasets\"\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(f\"Using accelerator '{device}'\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARN: No accelerator found, running on CPU\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalize by mean and standard devia,\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    batch_size=10000,\n",
    "    generator=torch.Generator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc1 = torch.nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Log softmax rather than softmax due to negative log likelihood loss.\n",
    "        # log_softmax rather than two separate operations for numerical stability\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log likelihood loss\n",
    "loss_function = torch.nn.functional.nll_loss\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: torch.nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer\n",
    ") -> None:\n",
    "    model.train()\n",
    "\n",
    "    for batch_features, batch_target in loader:\n",
    "        batch_features = typing.cast(torch.Tensor, batch_features).to(device)\n",
    "        batch_target = typing.cast(torch.Tensor, batch_target).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(batch_features)\n",
    "\n",
    "        batch_loss = loss_function(batch_output, batch_target)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the dataset into several chunks.\n",
    "\n",
    "We assign samples within chunks in an IID (independent and identically distributed) fashion or allow only two labels to exist in each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from components.metrics import RoundParameters, RunMetrics, RunResult\n",
    "from components.server import AbstractServer\n",
    "\n",
    "\n",
    "class CentralizedServer(AbstractServer):\n",
    "    def __init__(\n",
    "        self, model: torch.nn.Module, learning_rate: float, batch_size: int, seed: int\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            model,\n",
    "            RoundParameters(\n",
    "                clients_count=1,\n",
    "                active_clients_fraction=float(\"nan\"),\n",
    "                batch_size=batch_size,\n",
    "                local_epochs_count=1,\n",
    "                learning_rate=learning_rate,\n",
    "                seed=seed,\n",
    "            ),\n",
    "            device,\n",
    "        )\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            params=self.model.parameters(), lr=learning_rate\n",
    "        )\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            generator=self.generator,\n",
    "        )\n",
    "\n",
    "    def run(self, rounds: int) -> RunResult:\n",
    "        metrics = RunMetrics()\n",
    "\n",
    "        for epoch in tqdm(range(rounds), \"epoch\", leave=False):\n",
    "            self.generator.manual_seed(self.parameters.seed + epoch + 1)\n",
    "\n",
    "            wall_time_start = time.perf_counter()\n",
    "            train_epoch(self.model, self.loader_train, self.optimizer)\n",
    "            wall_time_end = time.perf_counter()\n",
    "\n",
    "            accuracy = self.evaluate_accuracy(test_loader)\n",
    "            execution_time = wall_time_end - wall_time_start\n",
    "\n",
    "            metrics.test_accuracy.append(accuracy)\n",
    "            metrics.wall_time.append(execution_time)\n",
    "            metrics.message_count.append(-1)\n",
    "\n",
    "        return RunResult(\"centralized\", self.parameters, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e17b2fd2ab64a359c46e7bfd880dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  8027 total:  10000\n",
      "correct:  9653 total:  10000\n",
      "correct:  9745 total:  10000\n",
      "correct:  9800 total:  10000\n",
      "correct:  9836 total:  10000\n"
     ]
    }
   ],
   "source": [
    "centralized_server = CentralizedServer(\n",
    "    model=MnistCnn().to(device), learning_rate=0.5, batch_size=1024, seed=42\n",
    ")\n",
    "result_centralized = centralized_server.run(rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clients_count</th>\n",
       "      <th>active_clients_fraction</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>local_epochs_count</th>\n",
       "      <th>Î·</th>\n",
       "      <th>seed</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>message_count (sum)</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>6.356011</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.8027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>6.104182</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>6.195448</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>6.093476</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>centralized</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>6.204228</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round    algorithm  clients_count  active_clients_fraction  batch_size  \\\n",
       "0      1  centralized              1                      NaN        1024   \n",
       "1      2  centralized              1                      NaN        1024   \n",
       "2      3  centralized              1                      NaN        1024   \n",
       "3      4  centralized              1                      NaN        1024   \n",
       "4      5  centralized              1                      NaN        1024   \n",
       "\n",
       "   local_epochs_count    Î·  seed  wall_time  message_count (sum)  \\\n",
       "0                   1  0.5    42   6.356011                   -1   \n",
       "1                   1  0.5    42   6.104182                   -1   \n",
       "2                   1  0.5    42   6.195448                   -1   \n",
       "3                   1  0.5    42   6.093476                   -1   \n",
       "4                   1  0.5    42   6.204228                   -1   \n",
       "\n",
       "   test_accuracy  \n",
       "0         0.8027  \n",
       "1         0.9653  \n",
       "2         0.9745  \n",
       "3         0.9800  \n",
       "4         0.9836  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
