{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using accelerator 'mps'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path = \"../../datasets\"\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(f\"Using accelerator '{device}'\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARN: No accelerator found, running on CPU\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalize by mean and standard devia,\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    batch_size=10000,\n",
    "    generator=torch.Generator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc1 = torch.nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Log softmax rather than softmax due to negative log likelihood loss.\n",
    "        # log_softmax rather than two separate operations for numerical stability\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not otherwise specified, use the following parameter values in experiment runs:\n",
    "- `nr_clients` (N): 100\n",
    "- `lr`: 0.01\n",
    "- `client_fraction` (C): 0.1\n",
    "- `nr_local_epochs` (E): 1\n",
    "- `batch_size` (B): 100\n",
    "- `nr_rounds`: 10\n",
    "- `iid`: True\n",
    "\n",
    "For all exercises, pass `seed = 10` to calls for splitting data, server initialization, or plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "clients = 100\n",
    "learning_rate = 0.01\n",
    "active_clients_fraction = 0.1\n",
    "local_epochs = 1\n",
    "batch_size = 100\n",
    "rounds = 10\n",
    "assume_data_iid = True\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A1: FedSGD with weights (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials. The two FedSGD versions should have the same test accuracy after each round (with a tolerance of up to around 0.1%). To show this, compare their output for the following two scenarios over *5 rounds*:\n",
    "- `lr = 0.01, client_subsets = split(100, True, ...), client_fraction = 0.5`\n",
    "- `lr = 0.1, client_subsets = split(50, False, ...), client_fraction = 0.2`\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required.\n",
    "\n",
    "_(1 point)_ Explain in which cases (for the different decentralized data learning parameters) weight and gradient FedSGD are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.data_splitting import (\n",
    "    index_uniformly,\n",
    "    index_by_approximate_binary_target_partitions,\n",
    "    partition_dataset,\n",
    ")\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def determine_client_datasets(iid: bool, clients: int) -> list[Subset]:\n",
    "    if iid:\n",
    "        partition_index = index_uniformly(train_dataset, clients, seed)\n",
    "    else:\n",
    "        partition_index = index_by_approximate_binary_target_partitions(\n",
    "            train_dataset, clients, seed\n",
    "        )\n",
    "\n",
    "    return partition_dataset(train_dataset, partition_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedavg import Server as FedAvgServer\n",
    "\n",
    "\n",
    "def run_fedavg(\n",
    "    iid: bool, clients: int, active_clients_fraction: float, learning_rate: float\n",
    ") -> pd.DataFrame:\n",
    "    partitions = determine_client_datasets(iid, clients)\n",
    "\n",
    "    server = FedAvgServer(\n",
    "        device=device,\n",
    "        model_builder=lambda: MnistCnn().to(device),\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=len(train_dataset),\n",
    "        client_subsets=partitions,\n",
    "        client_fraction=active_clients_fraction,\n",
    "        local_epochs=local_epochs,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    return server.run(5, test_loader).as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedsgd import Server as FedSgdServer\n",
    "\n",
    "\n",
    "def run_fedsgd(\n",
    "    iid: bool, clients: int, active_clients_fraction: float, learning_rate: float\n",
    ") -> pd.DataFrame:\n",
    "    partitions = determine_client_datasets(iid, clients)\n",
    "\n",
    "    fedsgd_server = FedSgdServer(\n",
    "        device=device,\n",
    "        model_builder=lambda: MnistCnn().to(device),\n",
    "        client_subsets=partitions,\n",
    "        active_clients_fraction=active_clients_fraction,\n",
    "        learning_rate=learning_rate,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    return fedsgd_server.run(5, test_loader).as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ad13906f7347df977fc99423526fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871c0e7f59ff45b98dadd50a15d9e281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8092d31bd30450dba9b83fe59458410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc54134ca4247f6bb59150b3827698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccaccc81eda44b2a590ace3156f0233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1daac58af946f3bdc2881f1a99b5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fedsgd_results = run_fedsgd(\n",
    "    iid=True, clients=100, active_clients_fraction=0.1, learning_rate=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da05a3e74fb40f38b7f732c621d8e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf6c9d3e2c4299a679b2e2db5214d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d4795cd9db455a9ca4da10f441a1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689a0c4cfd8547bbab53af555c8f4a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2967cac7bab04e678f2bfdb40298021a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1297fc66056c4c02b8d985b37154a2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fedavg_results = run_fedavg(\n",
    "    iid=True, clients=100, active_clients_fraction=0.1, learning_rate=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clients_count</th>\n",
       "      <th>active_clients_fraction</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>local_epochs_count</th>\n",
       "      <th>η</th>\n",
       "      <th>seed</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>message_count (sum)</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1.087110</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993595</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977105</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1.061754</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1.035281</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977731</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979972</td>\n",
       "      <td>80</td>\n",
       "      <td>0.2176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991840</td>\n",
       "      <td>80</td>\n",
       "      <td>0.2176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986630</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1.055012</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round algorithm  clients_count  active_clients_fraction batch_size  \\\n",
       "0      1    FedSgd            100                      0.1          ∞   \n",
       "0      1    FedAvg            100                      0.1      60000   \n",
       "1      2    FedSgd            100                      0.1          ∞   \n",
       "1      2    FedAvg            100                      0.1      60000   \n",
       "2      3    FedSgd            100                      0.1          ∞   \n",
       "2      3    FedAvg            100                      0.1      60000   \n",
       "3      4    FedSgd            100                      0.1          ∞   \n",
       "3      4    FedAvg            100                      0.1      60000   \n",
       "4      5    FedSgd            100                      0.1          ∞   \n",
       "4      5    FedAvg            100                      0.1      60000   \n",
       "\n",
       "   local_epochs_count     η  seed  wall_time  message_count (sum)  \\\n",
       "0                   1  0.01    10   1.087110                   20   \n",
       "0                   1  0.01    10   0.993595                   20   \n",
       "1                   1  0.01    10   0.977105                   40   \n",
       "1                   1  0.01    10   1.061754                   40   \n",
       "2                   1  0.01    10   1.035281                   60   \n",
       "2                   1  0.01    10   0.977731                   60   \n",
       "3                   1  0.01    10   0.979972                   80   \n",
       "3                   1  0.01    10   0.991840                   80   \n",
       "4                   1  0.01    10   0.986630                  100   \n",
       "4                   1  0.01    10   1.055012                  100   \n",
       "\n",
       "   test_accuracy  \n",
       "0         0.1247  \n",
       "0         0.1247  \n",
       "1         0.1519  \n",
       "1         0.1519  \n",
       "2         0.1816  \n",
       "2         0.1816  \n",
       "3         0.2176  \n",
       "3         0.2176  \n",
       "4         0.2573  \n",
       "4         0.2573  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([fedsgd_results, fedavg_results])\n",
    "df.sort_values(\"round\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A2: Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Run the necessary experiments to fill in the following table showing the final message count and test accuracy of FedSGD and FedAvg for different total client numbers:\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 |               |               |\n",
    "| FedAvg    | 10  | 0.1 |               |               |\n",
    "| FedSGD    | 50  | 0.1 |               |               |\n",
    "| FedAvg    | 50  | 0.1 |               |               |\n",
    "| FedSGD    | 100 | 0.1 |               |               |\n",
    "| FedAvg    | 100 | 0.1 |               |               |\n",
    "\n",
    "Is the relationship between the metrics/algorithms and client numbers monotonous? Briefly explain your reasoning.\n",
    "\n",
    "_(2 points)_ Run the experiments to fill in the table when varying the fraction of clients used in every round:\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 |               |               |\n",
    "| FedAvg    | 100 | 0.01 |               |               |\n",
    "| FedSGD    | 100 | 0.1  |               |               |\n",
    "| FedAvg    | 100 | 0.1  |               |               |\n",
    "| FedSGD    | 100 | 0.2  |               |               |\n",
    "| FedAvg    | 100 | 0.2  |               |               |\n",
    "\n",
    "How do the observed relationships compare to before? Again, succintly argue your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A3: Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Create a line plot of the accuracy after each round for the following algorithm variants:\n",
    "\n",
    "- FedSGD\n",
    "- FedAvg (E=1)\n",
    "- FedAvg (E=2)\n",
    "- FedAvg (E=4)\n",
    "\n",
    "How does FedAvg compare to FedSGD? What is the effect of increasing the work clients perform locally for each update in FedAvg?\n",
    "\n",
    "_(2 points)_ Make one line plot of FedSGD and FedAvg under an IID and non-IID split for 15 rounds (leaving all other parameter values as they previously mentioned default). How does the non-IID setting affect the accuracy achieved by the two algorithms? What is the difference in terms of the smoothness of learning?\n",
    "\n",
    "_(2 points)_ Make another plot for only non-IID splits, including the FedSGD and FedAvg configs from the point above, and add a version for each with a learning rate of 0.001 and client fraction of 0.5. How does the stability of the new variants compare to the ones from before? Why do the changes in parameters have the observed effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B1: Microbatch Pipeline Model Parallelism (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement pipeline parallelism with microbatches, as discussed during the lab.\n",
    "\n",
    "As with the other data/model parallelism examples, you will need a Python script for the nodes and a shell script to orchestrate execution.\n",
    "\n",
    "Be aware of the possibility of deadlocks: due to how `gloo` operates, it is possible to deadlock by having device 1 send $B_2$ to device 2 in the forward pass, and simultaneously, device 2 send $B_1$ in the backward pass.\n",
    "Since both sends will await corresponding receives, the training will stop indefinitely.\n",
    "\n",
    "Use `isend` & `irecv`, the asynchronous (non-blocking) versions of `send` & `recv` in `torch.distributed`.\n",
    "Each call of the two function returns a `Work` object, on which calling `wait()` blocks, if needed, until the message exchange finishes.\n",
    "Add comments or text explaining how you expect your implementation to work and test that it runs for the same number of steps and model architecture as in class.\n",
    "\n",
    "Note that `torch.distributed`'s implementation of `gloo` does not currently support properly asynchronous communication even when using the corresponding primitives.\n",
    "Thus, you will not see the same improvements in speed as with a backend like `nccl`.\n",
    "\n",
    "You may also use the fact that `torch` gradients naturally accumulate if zeroed out.\n",
    "Also, scaling the loss by a constant is equivalent to scaling the resulting gradients by the same constant.\n",
    "\n",
    "You can rely on receiving messages in the same order they get sent between any device pair.\n",
    "The `(i)send/recv` functions all support a `tag` attribute to match messages explicitly.\n",
    "Although using it is good practice, it is not required.\n",
    "\n",
    "You can refer to the [documentation](https://pytorch.org/docs/stable/distributed.html) and, if helpful, a related [tutorial](https://brsoff.github.io/tutorials/intermediate/dist_tuto.html) on the PyTorch website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B2: Joint Data & Model Parallelism (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a training setup that uses data and model parallelism together.\n",
    "\n",
    "Create 2 pipelines of 3 stages running sequentially, where each stage works with 3 sequential micro-batches.\n",
    "\n",
    "Once again, add comments or text explaining your implementation and test it on the setting that mimics those from the class.\n",
    "\n",
    "You can use groups from `torch.distributed` to handle operations that require interaction between a subset of more than two but less than all workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
