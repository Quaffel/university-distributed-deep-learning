{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using accelerator 'mps'\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import torch\n",
    "from components.metrics import RunMetrics, RunResult\n",
    "from components.tensor_types import IndexVector\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_path = \"../../datasets\"\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(f\"Using accelerator '{device}'\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARN: No accelerator found, running on CPU\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalize by mean and standard devia,\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    batch_size=10000,\n",
    "    generator=torch.Generator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc1 = torch.nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Log softmax rather than softmax due to negative log likelihood loss.\n",
    "        # log_softmax rather than two separate operations for numerical stability\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.client import AbstractClient\n",
    "\n",
    "# negative log likelihood loss\n",
    "loss_function = torch.nn.functional.nll_loss\n",
    "\n",
    "\n",
    "class GradientClient(AbstractClient):\n",
    "    def __init__(self, model: torch.nn.Module, client_data: Subset) -> None:\n",
    "        client_data_size = len(client_data)\n",
    "\n",
    "        super().__init__(model, client_data, client_data_size)\n",
    "        self.client_data_size = client_data_size\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        self.generator.manual_seed(seed)\n",
    "        model = self.build_local_model(weights)\n",
    "\n",
    "        model.train()\n",
    "        for batch_features, batch_target in self.loader_train:\n",
    "            batch_features = typing.cast(torch.Tensor, batch_features).to(device)\n",
    "            batch_target = typing.cast(torch.Tensor, batch_target).to(device)\n",
    "\n",
    "            batch_output = model(batch_features)\n",
    "\n",
    "            batch_loss = loss_function(batch_output, batch_target)\n",
    "            batch_loss.backward()\n",
    "\n",
    "        parameter_gradients = [\n",
    "            typing.cast(torch.Tensor, param.grad).detach().cpu()\n",
    "            for param in model.parameters()\n",
    "        ]\n",
    "        return parameter_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from components.server import DecentralizedServer\n",
    "\n",
    "\n",
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        client_subsets: list[Subset],\n",
    "        active_clients_fraction: float,\n",
    "        learning_rate: float,\n",
    "        seed: int,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            client_subsets=client_subsets,\n",
    "            active_clients_fraction=active_clients_fraction,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=-1,\n",
    "            seed=seed,\n",
    "            device=device,\n",
    "        )\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            params=self.model.parameters(), lr=learning_rate\n",
    "        )\n",
    "        self.clients: list[GradientClient] = [\n",
    "            GradientClient(model, subset) for subset in client_subsets\n",
    "        ]\n",
    "        self.client_datasets = client_subsets\n",
    "\n",
    "    def select_clients(self) -> IndexVector:\n",
    "        return self.generator.choice(len(self.clients), self.clients_per_round)\n",
    "\n",
    "    def calculate_gradient_fraction_for_client(\n",
    "        self,\n",
    "        client: GradientClient,\n",
    "        weights: list[torch.Tensor],\n",
    "        seed: int,\n",
    "        total_epoch_dataset_size: int,\n",
    "    ) -> list[torch.Tensor]:\n",
    "        client_dataset_size = client.client_data_size\n",
    "\n",
    "        return [\n",
    "            client_dataset_size / total_epoch_dataset_size * parameter_gradient\n",
    "            for parameter_gradient in client.update(weights, seed)\n",
    "        ]\n",
    "\n",
    "    def run_epoch(self, weights: list[torch.Tensor], epoch: int):\n",
    "        client_indices = self.select_clients()\n",
    "        client_dataset_size = sum(\n",
    "            len(self.clients[client_idx].loader_train) for client_idx in client_indices\n",
    "        )\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # N x M; N clients with gradients for M parameters each\n",
    "        gradients = [\n",
    "            self.calculate_gradient_fraction_for_client(\n",
    "                self.clients[client_idx],\n",
    "                weights,\n",
    "                seed=self.parameters.seed + epoch + 1,\n",
    "                total_epoch_dataset_size=client_dataset_size,\n",
    "            )\n",
    "            for client_idx in tqdm(client_indices, \"clients\")\n",
    "        ]\n",
    "\n",
    "        aggregated_gradient: list[torch.Tensor] = [\n",
    "            # sum gradients parameter-wise; 'parameter_gradients' is a tuple that contains one gradient per client\n",
    "            torch.stack(parameter_gradients, dim=0).sum(dim=0)\n",
    "            for parameter_gradients in zip(*gradients)\n",
    "        ]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for parameter, parameter_gradient in zip(\n",
    "                self.model.parameters(), aggregated_gradient\n",
    "            ):\n",
    "                parameter.grad = parameter_gradient.to(device)\n",
    "\n",
    "        self.model.train()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def run(self, rounds: int) -> RunResult:\n",
    "        metrics = RunMetrics()\n",
    "\n",
    "        for epoch in tqdm(range(rounds), \"epoch\", leave=False):\n",
    "            weights = [\n",
    "                parameter.detach().clone() for parameter in self.model.parameters()\n",
    "            ]\n",
    "\n",
    "            wall_clock_start = time.perf_counter()\n",
    "            weights = self.run_epoch(weights, epoch)\n",
    "            wall_clock_end = time.perf_counter()\n",
    "\n",
    "            accuracy = self.evaluate_accuracy(test_loader)\n",
    "            execution_time_s = wall_clock_end - wall_clock_start\n",
    "\n",
    "            metrics.test_accuracy.append(accuracy)\n",
    "            metrics.wall_time.append(execution_time_s)\n",
    "            metrics.message_count.append(2 * self.clients_per_round * (epoch + 1))\n",
    "\n",
    "        return RunResult(\"FedSgd\", self.parameters, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ffb2c5c355408abc3f714ad306aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784e9c5dc0cf498aad2b0a63569d59c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  980 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca11a7ab86af4b87843bb274d26e01ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  974 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96739597f3654148adadd56f5e3aa661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  1010 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa576c731c940e58a79c018331dbd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  958 total:  10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f477ec5a2c254cdcb3a50917e33c125b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clients:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  1009 total:  10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clients_count</th>\n",
       "      <th>active_clients_fraction</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>local_epochs_count</th>\n",
       "      <th>η</th>\n",
       "      <th>seed</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>message_count (sum)</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>9.774599</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>9.888583</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>9.983670</td>\n",
       "      <td>120</td>\n",
       "      <td>0.1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>9.797172</td>\n",
       "      <td>160</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FedSgd</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>∞</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>42</td>\n",
       "      <td>10.074224</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round algorithm  clients_count  active_clients_fraction batch_size  \\\n",
       "0      1    FedSgd             20                        1          ∞   \n",
       "1      2    FedSgd             20                        1          ∞   \n",
       "2      3    FedSgd             20                        1          ∞   \n",
       "3      4    FedSgd             20                        1          ∞   \n",
       "4      5    FedSgd             20                        1          ∞   \n",
       "\n",
       "   local_epochs_count     η  seed  wall_time  message_count (sum)  \\\n",
       "0                   1  0.02    42   9.774599                   40   \n",
       "1                   1  0.02    42   9.888583                   80   \n",
       "2                   1  0.02    42   9.983670                  120   \n",
       "3                   1  0.02    42   9.797172                  160   \n",
       "4                   1  0.02    42  10.074224                  200   \n",
       "\n",
       "   test_accuracy  \n",
       "0         0.0980  \n",
       "1         0.0974  \n",
       "2         0.1010  \n",
       "3         0.0958  \n",
       "4         0.1009  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from components.data_splitting import (\n",
    "    index_by_approximate_binary_target_partitions,\n",
    "    partition_dataset,\n",
    ")\n",
    "\n",
    "client_datasets = partition_dataset(\n",
    "    train_dataset,\n",
    "    index_by_approximate_binary_target_partitions(\n",
    "        train_dataset, partitions_count=20, generator_or_seed=42\n",
    "    ),\n",
    ")\n",
    "\n",
    "fedsgd_gradient_server = FedSgdGradientServer(\n",
    "    model=MnistCnn().to(device),\n",
    "    client_subsets=client_datasets,\n",
    "    active_clients_fraction=1,\n",
    "    learning_rate=0.02,\n",
    "    seed=42,\n",
    ")\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
